\section{Общая постановка задачи}

Рассматриваются два игрока -- Студент, далее обозначается \textbf{С},
и Преподаватель, далее обозначается \textbf{П}, которые имеют противоположные 
интересы. Критерий интересов составляют две величины, первая из которых
является эффективностью работы \textbf{С} в научной сфере, а вторая -- его 
эффективностью на подработке.

\textbf{С} выбирает долю $x$ рабочего времени, которую он тратит на подготовку
диплома, оставшееся рабочее время $1-x$ он тратит на подработку. Считается, что 
производительность \textbf{С} при любых занятий падает с увеличением 
отводимого на них времени, поэтому эффективность труда \textbf{С} зададим 
функцией $\sqrt{x}$ и $\sqrt{1-x}$ соответственно. \textbf{С} может 
распределять свое время между двумя 
видами деятельности, т.е. имеет множество стратегий $x\in X = [0, 1]$, 
причём он может использовать смешанные стратегии.

\textbf{П} выбирает -- относиться к \textbf{С} требовательно, способствуя 
написанию диплома и мешая подработке или же не мешать подработке и не помогать
\textbf{С}с дипломом. \textbf{П} имеет множество стратегий 
$y \in Y=\{1, 2\}$, причём тоже может использовать смешанные стратегии.

Определим вектор-функцию выигрыша следующим образом:
\begin{equation}
	F(x, y)=
	\big(f_1(x,y), f_2(x,y)\big) =
	\Big(
		\frac{y\sqrt{x}}2,
		\frac{\sqrt{1-x}}y
	\Big)
	\label{eq:player_criterion}
\end{equation}

\textbf{П} стремится минимизировать (выбирая $y \in Y = \{1,2\}$)
вектор-функцию выигрыша $F(x, y)$, а игрок \textbf{С} - максимизировать
 (выбирая $x \in X=[0,1]$).

Мы будем рассматривать конечную игру \textbf{C --- П}, полученную из исходной дискретизацией множества $X$ конечным множеством точек:
$$
	X^T = \{
		0, \; 
		\frac{1}{T}, \; 
		\frac{2}{T}, \; 
		\ldots, \; 
		\frac{T-1}{T}, \;
		1
	\}, \;\; T \in \mathbb{N}
$$

Поскольку игроки используют смешанные стратегии, определим допустимые
распределения $q$ и $p$ зависимые от параметра дискретизации $T$ для игрока
 \textbf{С} и \textbf{П} соответственно:
\begin{equation}
	\label{eq:P_T}
	q \in Q(T)
	= \{ 
		(q_1, \ldots , q_{T+1}) \in [0,1]^{T+1}\: | \:
		\sum \limits_{i=1}^{T+1} q_i = 1
	\}
\end{equation}
\begin{equation}
	\label{eq:Q}
	p \in P
	= \{ 
		(p_1, p_2) \in [0,1]^2\: | \:
		p_1 + p_2 = 1
	\}
\end{equation}

Теперь задачу можно представить в виде многокритериальной игры двух лиц 
с противоположными интересами:
\begin{equation}
	G = \big \langle A, S, \textbf{F} \big \rangle
\end{equation}
	где: 
 
	$ A = $\{\textbf{C}, \textbf{П}\} -- множество игроков,

	$ S = \{Q(T), \, T\}$ -- множество наборов смешанных
	стратегий игроков,
	
	$ \textbf{F} = \{F, \, -F\}$ -- множество вектор-функций выигрыша
	игроков.
\newline 
В работе исследуются случаи дискретизации, когда $T=1$ и тогда 
множество $X^1=\{0, 1\}$, и когда 
$T=2$, тогда множество чистых стратегий \textbf{С}
принимает вид $X^2=\{0, \frac{1}{2} ,1\}$.
В каждом случае необходимо решить игру, т.е. найти
равновесия Нэша в смешанных стратегиях. Составим план, по которому
будет проходить поиск решений \eqref{eq:ext_normal_form_game}.

\hspace{3mm}

\textbf{(1)} 
Игроки используют смешанные стратегии, поэтому стратегий \textbf{С} и
\textbf{П} будет распределение вероятностей $q \in Q(T)$ и 
$p \in P$ над множествами $X^T$ и $Y$
соответственно. Где $Q(T)$ и $P$ -- все допустимые
распределения над этими множествами.
Следовательно заменим вектор-функцию выигрыша каждого
игрока на математическое ожидание этой функции по распределению вероятностей его
стратегии. Для \textbf{С} и \textbf{П} функции принимают вид 
$\mathbb{E}_x [F(x,y)]$ и $\mathbb{E}_y [-F(x,y)]$:
\begin{gather*}
	\mathbb{E}_x [F(x,y)] = 
	\big \langle
		\mathbb{E}_{x}[f_1(x,y)], \mathbb{E}_{x}[f_2(x, y)]
	\big \rangle
	\\
	\mathbb{E}_y [-F(x,y)] = 
	\big \langle
		\mathbb{E}_{y}[-f_1(x,y)], \mathbb{E}_{y}[-f_2(x, y)]
	\big \rangle
\end{gather*}

\textbf{(2)}
Каждый игрок выбирает функцию свёртки, которая будет аппроксимировать его
множество Слейтера $S_a$. В данной работе исследуется случай, когда
игрок \textbf{С} выбирает \textit{обратную логическую свёртку}, 
а игрок \textbf{П} \textit{линейную свёртку}. После чего игроки 
применяют свёртку к осреднённой вектор-функции выигрыша.
Для \textbf{С} и \textbf{П} скаляризованные функции выигрыша принимают вид:
\begin{gather*}
	G(\mathbb{E}_x [F(x,y)], q, y, \mu)
	\\
	L(\mathbb{E}_y [-F(x,y)], x, p, \lambda).
\end{gather*}

\textbf{(3)}
Далее игроки получают скалярный критерий, который зависит от 
чистых стратегий противника. Поскольку игроки используют смешанные стратегии,
то и рассчитывать на средний выигрыш, поэтому
теперь каждый осредняет скаляризованные критерии по 
стратегиям противника. Мы получили функции выигрыша игроков, которые
зависят от их смешанных стратегий.
Для \textbf{С} и \textbf{П} функции выигрыша принимают вид 
\begin{gather*}
	\overline G(p, q, \mu) =
	\mathbb{E}_y [G(\mathbb{E}_x [F(x,y)], q, y, \mu)]
	\\
	\overline L(p, q, \lambda) = 
	\mathbb{E}_x [L(\mathbb{E}_y [-F(x,y)], x, p, \lambda)].
\end{gather*}

\textbf{(4)}
Мы получили игру в смешанных стратегиях и теперь
необходимо найти все возможные равновесия Нэша \eqref{eq:nash_equilibrium}
при фиксированных параметрах свёртки. 
Стратегии, которые являются решениями будем называть 
\textit{оптимальными стратегиями}. В конкретном случае они определяются
следующим образом:

\begin{Defenition}	
	Пара стратегий $(p^0, q^0) \in P(T) \times Q$
	называется оптимальными, если для некоторой пары параметров 
	$(\lambda, \mu) \in \Lambda \times M$ верно:
	\begin{equation}
		\begin{cases} 
			p^0(q^0, \lambda) = 
			\arg \min \limits_{p \in P} \overline L(p, q^0, \lambda) \\ 
			q^0(p^0, \mu) = 
			\arg \min \limits_{q \in Q} \overline G(p^0, q, \mu) \\
		\end{cases}
	\label{def:optimal_strategy}
	\end{equation}
Использованы следующие обозначения:
	\begin{gather*}
		\arg \max \limits_{x \in X} f(x) = 
		\{ x^* \in X \: | \: f(x^*) = \max \limits_{x \in X} f(x)\}
		\\
		\arg \min \limits_{x \in X} f(x) = 
		\{ x^* \in X \: | \: f(x^*) = \min \limits_{x \in X} f(x)\}
	\end{gather*}
	Множество всех оптимальных пар обозначим через $\mathbb{O}_T$,
	где $T$ -- означает степень дискретизации для конкретной задачи.
\end{Defenition}
